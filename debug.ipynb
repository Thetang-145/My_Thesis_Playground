{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18310ccd-b785-4454-a585-17a51016fa4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8475d77c-96d6-4fed-8e3a-4d412bee417c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(dt_split='val', i=None, dataset=\"arXiv\", section=\"abstract\"):\n",
    "    \n",
    "    if isinstance(i, int) and dataset==\"arXiv\":\n",
    "        filepath = f\"PL-Marker/_prepared_data/{dataset}/{section}/{dt_split}_{i}.jsonl\"\n",
    "    else:\n",
    "        filepath = f\"PL-Marker/_prepared_data/{dataset}/{section}/{dt_split}.jsonl\"\n",
    "    with open(filepath, 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "    dataset = []\n",
    "    for i, json_str in enumerate(json_list):\n",
    "        line = json.loads(json_str)\n",
    "        dataset.append({\n",
    "            \"paper_id\": line['doc_key'],\n",
    "            \"sentences\": line['sentences'],\n",
    "        })\n",
    "    df = pd.DataFrame(dataset)\n",
    "    n = ([len(doc) for doc in list(df['sentences'])])\n",
    "    df['num_sentences'] = n\n",
    "    return df\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81ee06cb-db86-469d-9f54-5f03318389cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sentences</th>\n",
       "      <th>num_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1009.3123</td>\n",
       "      <td>[[ , the, short, -, term, periodicities, of, t...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1512.09139</td>\n",
       "      <td>[[ , we, study, the, detectability, of, circul...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0909.1602</td>\n",
       "      <td>[[ , starting, from, the, wkb, approximation, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1512.03812</td>\n",
       "      <td>[[ , we, study, a, novel, class, of, numerical...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1512.09024</td>\n",
       "      <td>[[ , new, methods, for, obtaining, functional,...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6435</th>\n",
       "      <td>1506.04611</td>\n",
       "      <td>[[ , we, explain, how, hierarchical, organizat...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6436</th>\n",
       "      <td>1509.09138</td>\n",
       "      <td>[[ , this, work, presents, a, smart, trespasse...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6437</th>\n",
       "      <td>astro-ph0504395</td>\n",
       "      <td>[[ , the, giant, radio, galaxy, m87, was, obse...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6438</th>\n",
       "      <td>0911.3417</td>\n",
       "      <td>[[ , the, discovery, of, decay, products, of, ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6439</th>\n",
       "      <td>cs0506073</td>\n",
       "      <td>[[ , an, iterative, algorithm, is, presented, ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6440 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             paper_id                                          sentences  \\\n",
       "0           1009.3123  [[ , the, short, -, term, periodicities, of, t...   \n",
       "1          1512.09139  [[ , we, study, the, detectability, of, circul...   \n",
       "2           0909.1602  [[ , starting, from, the, wkb, approximation, ...   \n",
       "3          1512.03812  [[ , we, study, a, novel, class, of, numerical...   \n",
       "4          1512.09024  [[ , new, methods, for, obtaining, functional,...   \n",
       "...               ...                                                ...   \n",
       "6435       1506.04611  [[ , we, explain, how, hierarchical, organizat...   \n",
       "6436       1509.09138  [[ , this, work, presents, a, smart, trespasse...   \n",
       "6437  astro-ph0504395  [[ , the, giant, radio, galaxy, m87, was, obse...   \n",
       "6438        0911.3417  [[ , the, discovery, of, decay, products, of, ...   \n",
       "6439        cs0506073  [[ , an, iterative, algorithm, is, presented, ...   \n",
       "\n",
       "      num_sentences  \n",
       "0                 6  \n",
       "1                 5  \n",
       "2                 4  \n",
       "3                 3  \n",
       "4                 7  \n",
       "...             ...  \n",
       "6435             10  \n",
       "6436              3  \n",
       "6437              6  \n",
       "6438              6  \n",
       "6439              8  \n",
       "\n",
       "[6440 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3a9ae57-a3e8-4536-a3cb-d54dca1afd19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def boxplot(df):\n",
    "    # Set the figure size\n",
    "    plt.rcParams[\"figure.figsize\"] = [5, 3.50]\n",
    "    plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "    # plt.figure(figsize=(5, 4)) #for a bigger image\n",
    "    sns.boxplot(y=\"num_sentences\", data=df, palette=\"Set1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db2dea25-1031-4e5b-9a1b-088cb056eab5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sentences</th>\n",
       "      <th>num_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:b19df5243359791fbaad005d6f13d7e9fdb0ff63</td>\n",
       "      <td>[[Cooperative, multi, -, agent, problems, are,...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP:7deb61890d97422a0fe141ca807f968c70ab239a</td>\n",
       "      <td>[[Gradient, descent, (, GD, ), and, subgradien...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP:c7e0b3fedc0d0409d662dd612b529fdacad2b03e</td>\n",
       "      <td>[[We, demonstrate, that, transformers, obtain,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP:ba9f1d4738ec67a440346f3ac6c4cf35f7232077</td>\n",
       "      <td>[[Beyond, the, well, -, known, property, of, e...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP:c1116fbb4d058eb6be195b5d13d19a55ba86b602</td>\n",
       "      <td>[[In, recent, years, ,, there, has, been, a, r...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>SP:0df5ad333eb4ff9cca7f2d117909e2ce533a65d8</td>\n",
       "      <td>[[Conditional, text, generation, is, the, task...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>SP:03307deac29173b2968fbd08f95fc77eb1f82410</td>\n",
       "      <td>[[The, “, magnitude, -, equals, -, saliency, ”...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>SP:dc80fdc75bc14ae19fe4ba9b85c35ce00b12856f</td>\n",
       "      <td>[[1, INTRODUCTION, \\n, Stochastic, gradient, d...</td>\n",
       "      <td>1493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>SP:86c61a658d07ab86e2d84cef7e480bf7a06e4ddb</td>\n",
       "      <td>[[In, reinforcement, learning, ,, we, can, lea...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>SP:c70479b2096a52584b242de58272ca8d8565feea</td>\n",
       "      <td>[[This, paper, aims, to, develop, a, new, prob...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1052 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         paper_id  \\\n",
       "0     SP:b19df5243359791fbaad005d6f13d7e9fdb0ff63   \n",
       "1     SP:7deb61890d97422a0fe141ca807f968c70ab239a   \n",
       "2     SP:c7e0b3fedc0d0409d662dd612b529fdacad2b03e   \n",
       "3     SP:ba9f1d4738ec67a440346f3ac6c4cf35f7232077   \n",
       "4     SP:c1116fbb4d058eb6be195b5d13d19a55ba86b602   \n",
       "...                                           ...   \n",
       "1047  SP:0df5ad333eb4ff9cca7f2d117909e2ce533a65d8   \n",
       "1048  SP:03307deac29173b2968fbd08f95fc77eb1f82410   \n",
       "1049  SP:dc80fdc75bc14ae19fe4ba9b85c35ce00b12856f   \n",
       "1050  SP:86c61a658d07ab86e2d84cef7e480bf7a06e4ddb   \n",
       "1051  SP:c70479b2096a52584b242de58272ca8d8565feea   \n",
       "\n",
       "                                              sentences  num_sentences  \n",
       "0     [[Cooperative, multi, -, agent, problems, are,...             33  \n",
       "1     [[Gradient, descent, (, GD, ), and, subgradien...             16  \n",
       "2     [[We, demonstrate, that, transformers, obtain,...              2  \n",
       "3     [[Beyond, the, well, -, known, property, of, e...             23  \n",
       "4     [[In, recent, years, ,, there, has, been, a, r...             26  \n",
       "...                                                 ...            ...  \n",
       "1047  [[Conditional, text, generation, is, the, task...             20  \n",
       "1048  [[The, “, magnitude, -, equals, -, saliency, ”...             18  \n",
       "1049  [[1, INTRODUCTION, \\n, Stochastic, gradient, d...           1493  \n",
       "1050  [[In, reinforcement, learning, ,, we, can, lea...              5  \n",
       "1051  [[This, paper, aims, to, develop, a, new, prob...             24  \n",
       "\n",
       "[1052 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_data('test', dataset=\"MuP\", section=\"section_1\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3dcbbc33-07be-4e09-8b50-ba5dc7019613",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a69391d-fdb0-4baf-96e8-01f1e68b591b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sentences</th>\n",
       "      <th>num_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:b19df5243359791fbaad005d6f13d7e9fdb0ff63</td>\n",
       "      <td>[[Cooperative, multi, -, agent, problems, are,...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP:7deb61890d97422a0fe141ca807f968c70ab239a</td>\n",
       "      <td>[[Gradient, descent, (, GD, ), and, subgradien...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP:c7e0b3fedc0d0409d662dd612b529fdacad2b03e</td>\n",
       "      <td>[[We, demonstrate, that, transformers, obtain,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP:ba9f1d4738ec67a440346f3ac6c4cf35f7232077</td>\n",
       "      <td>[[Beyond, the, well, -, known, property, of, e...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP:c1116fbb4d058eb6be195b5d13d19a55ba86b602</td>\n",
       "      <td>[[In, recent, years, ,, there, has, been, a, r...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>SP:0df5ad333eb4ff9cca7f2d117909e2ce533a65d8</td>\n",
       "      <td>[[Conditional, text, generation, is, the, task...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>SP:03307deac29173b2968fbd08f95fc77eb1f82410</td>\n",
       "      <td>[[The, “, magnitude, -, equals, -, saliency, ”...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>SP:dc80fdc75bc14ae19fe4ba9b85c35ce00b12856f</td>\n",
       "      <td>[[1, INTRODUCTION, \\n, Stochastic, gradient, d...</td>\n",
       "      <td>1493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>SP:86c61a658d07ab86e2d84cef7e480bf7a06e4ddb</td>\n",
       "      <td>[[In, reinforcement, learning, ,, we, can, lea...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>SP:c70479b2096a52584b242de58272ca8d8565feea</td>\n",
       "      <td>[[This, paper, aims, to, develop, a, new, prob...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1052 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         paper_id  \\\n",
       "0     SP:b19df5243359791fbaad005d6f13d7e9fdb0ff63   \n",
       "1     SP:7deb61890d97422a0fe141ca807f968c70ab239a   \n",
       "2     SP:c7e0b3fedc0d0409d662dd612b529fdacad2b03e   \n",
       "3     SP:ba9f1d4738ec67a440346f3ac6c4cf35f7232077   \n",
       "4     SP:c1116fbb4d058eb6be195b5d13d19a55ba86b602   \n",
       "...                                           ...   \n",
       "1047  SP:0df5ad333eb4ff9cca7f2d117909e2ce533a65d8   \n",
       "1048  SP:03307deac29173b2968fbd08f95fc77eb1f82410   \n",
       "1049  SP:dc80fdc75bc14ae19fe4ba9b85c35ce00b12856f   \n",
       "1050  SP:86c61a658d07ab86e2d84cef7e480bf7a06e4ddb   \n",
       "1051  SP:c70479b2096a52584b242de58272ca8d8565feea   \n",
       "\n",
       "                                              sentences  num_sentences  \n",
       "0     [[Cooperative, multi, -, agent, problems, are,...             33  \n",
       "1     [[Gradient, descent, (, GD, ), and, subgradien...             16  \n",
       "2     [[We, demonstrate, that, transformers, obtain,...              2  \n",
       "3     [[Beyond, the, well, -, known, property, of, e...             23  \n",
       "4     [[In, recent, years, ,, there, has, been, a, r...             26  \n",
       "...                                                 ...            ...  \n",
       "1047  [[Conditional, text, generation, is, the, task...             20  \n",
       "1048  [[The, “, magnitude, -, equals, -, saliency, ”...             18  \n",
       "1049  [[1, INTRODUCTION, \\n, Stochastic, gradient, d...           1493  \n",
       "1050  [[In, reinforcement, learning, ,, we, can, lea...              5  \n",
       "1051  [[This, paper, aims, to, develop, a, new, prob...             24  \n",
       "\n",
       "[1052 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_data('test', dataset=\"MuP\", section=\"section_1\")\n",
    "n = ([len(doc) for doc in list(df['sentences'])])\n",
    "df['num_sentences'] = n\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b95aa41-5d0b-49b2-ad8d-65593d7e6785",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sentences</th>\n",
       "      <th>num_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1009.3123</td>\n",
       "      <td>[[ , the, short, -, term, periodicities, of, t...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1512.09139</td>\n",
       "      <td>[[ , we, study, the, detectability, of, circul...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0909.1602</td>\n",
       "      <td>[[ , starting, from, the, wkb, approximation, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1512.03812</td>\n",
       "      <td>[[ , we, study, a, novel, class, of, numerical...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1512.09024</td>\n",
       "      <td>[[ , new, methods, for, obtaining, functional,...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6435</th>\n",
       "      <td>1506.04611</td>\n",
       "      <td>[[ , we, explain, how, hierarchical, organizat...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6436</th>\n",
       "      <td>1509.09138</td>\n",
       "      <td>[[ , this, work, presents, a, smart, trespasse...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6437</th>\n",
       "      <td>astro-ph0504395</td>\n",
       "      <td>[[ , the, giant, radio, galaxy, m87, was, obse...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6438</th>\n",
       "      <td>0911.3417</td>\n",
       "      <td>[[ , the, discovery, of, decay, products, of, ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6439</th>\n",
       "      <td>cs0506073</td>\n",
       "      <td>[[ , an, iterative, algorithm, is, presented, ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6440 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             paper_id                                          sentences  \\\n",
       "0           1009.3123  [[ , the, short, -, term, periodicities, of, t...   \n",
       "1          1512.09139  [[ , we, study, the, detectability, of, circul...   \n",
       "2           0909.1602  [[ , starting, from, the, wkb, approximation, ...   \n",
       "3          1512.03812  [[ , we, study, a, novel, class, of, numerical...   \n",
       "4          1512.09024  [[ , new, methods, for, obtaining, functional,...   \n",
       "...               ...                                                ...   \n",
       "6435       1506.04611  [[ , we, explain, how, hierarchical, organizat...   \n",
       "6436       1509.09138  [[ , this, work, presents, a, smart, trespasse...   \n",
       "6437  astro-ph0504395  [[ , the, giant, radio, galaxy, m87, was, obse...   \n",
       "6438        0911.3417  [[ , the, discovery, of, decay, products, of, ...   \n",
       "6439        cs0506073  [[ , an, iterative, algorithm, is, presented, ...   \n",
       "\n",
       "      num_sentences  \n",
       "0                 6  \n",
       "1                 5  \n",
       "2                 4  \n",
       "3                 3  \n",
       "4                 7  \n",
       "...             ...  \n",
       "6435             10  \n",
       "6436              3  \n",
       "6437              6  \n",
       "6438              6  \n",
       "6439              8  \n",
       "\n",
       "[6440 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = load_data('test')\n",
    "n = ([len(doc) for doc in list(df_val['sentences'])])\n",
    "df_val['num_sentences'] = n\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "559e3acf-d504-45ed-a22d-a36c0e75b881",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sentences</th>\n",
       "      <th>num_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1405.3379</td>\n",
       "      <td>[[ , additive, models, play, an, important, ro...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0901.1147</td>\n",
       "      <td>[[ , we, have, studied, the, leptonic, decay, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nlin0608019</td>\n",
       "      <td>[[ , in, 84, ,, 258, (, 2000, ), ,, mateos, co...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0903.5449</td>\n",
       "      <td>[[ , the, effect, of, a, random, phase, diffus...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hep-ph0605279</td>\n",
       "      <td>[[ , with, a, special, intention, of, clarifyi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24649</th>\n",
       "      <td>quant-ph0402038</td>\n",
       "      <td>[[ , effects, of, a, corrupt, source, on, the,...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24650</th>\n",
       "      <td>0907.3736</td>\n",
       "      <td>[[ , we, compute, the, entropy, of, antiferrom...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24651</th>\n",
       "      <td>1506.04688</td>\n",
       "      <td>[[ , as, a, generalization, of, orbit, -, poly...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24652</th>\n",
       "      <td>cond-mat0304118</td>\n",
       "      <td>[[ , within, the, lowest, -, order, born, appr...</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24653</th>\n",
       "      <td>0801.2228</td>\n",
       "      <td>[[ , conducting, submicron, particles, are, we...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203037 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              paper_id                                          sentences  \\\n",
       "0            1405.3379  [[ , additive, models, play, an, important, ro...   \n",
       "1            0901.1147  [[ , we, have, studied, the, leptonic, decay, ...   \n",
       "2          nlin0608019  [[ , in, 84, ,, 258, (, 2000, ), ,, mateos, co...   \n",
       "3            0903.5449  [[ , the, effect, of, a, random, phase, diffus...   \n",
       "4        hep-ph0605279  [[ , with, a, special, intention, of, clarifyi...   \n",
       "...                ...                                                ...   \n",
       "24649  quant-ph0402038  [[ , effects, of, a, corrupt, source, on, the,...   \n",
       "24650        0907.3736  [[ , we, compute, the, entropy, of, antiferrom...   \n",
       "24651       1506.04688  [[ , as, a, generalization, of, orbit, -, poly...   \n",
       "24652  cond-mat0304118  [[ , within, the, lowest, -, order, born, appr...   \n",
       "24653        0801.2228  [[ , conducting, submicron, particles, are, we...   \n",
       "\n",
       "       num_sentences  \n",
       "0                  6  \n",
       "1                  2  \n",
       "2                  9  \n",
       "3                  4  \n",
       "4                  4  \n",
       "...              ...  \n",
       "24649            155  \n",
       "24650              6  \n",
       "24651              7  \n",
       "24652            204  \n",
       "24653              4  \n",
       "\n",
       "[203037 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for i in range(6):\n",
    "    print(i)\n",
    "    df_ = load_data('train', i+1)\n",
    "    df = pd.concat([df, df_], axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea4164de-4778-4866-a5af-cd7e86cf1e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sentences</th>\n",
       "      <th>num_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1607.05158</td>\n",
       "      <td>[[ , we, report, on, strong, enhancement, of, ...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>1406.2707</td>\n",
       "      <td>[[ , we, describe, the, fundamental, construct...</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1703.08946</td>\n",
       "      <td>[[ , we, study, a, noisy, kuramoto, -, sivashi...</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>1303.4058</td>\n",
       "      <td>[[ , single, photon, sources, based, on, semic...</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0704.3553</td>\n",
       "      <td>[[ , we, show, that, the, centrality, and, sys...</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24544</th>\n",
       "      <td>hep-ph9808244</td>\n",
       "      <td>[[ , the, interplay, between, gaugino, condens...</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24569</th>\n",
       "      <td>1102.0174</td>\n",
       "      <td>[[ , while, crystalline, two, -, dimensional, ...</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24630</th>\n",
       "      <td>hep-ph0110404</td>\n",
       "      <td>[[ , the, diffractive, photoproduction, of, ve...</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24649</th>\n",
       "      <td>quant-ph0402038</td>\n",
       "      <td>[[ , effects, of, a, corrupt, source, on, the,...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24652</th>\n",
       "      <td>cond-mat0304118</td>\n",
       "      <td>[[ , within, the, lowest, -, order, born, appr...</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4497 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              paper_id                                          sentences  \\\n",
       "6           1607.05158  [[ , we, report, on, strong, enhancement, of, ...   \n",
       "156          1406.2707  [[ , we, describe, the, fundamental, construct...   \n",
       "194         1703.08946  [[ , we, study, a, noisy, kuramoto, -, sivashi...   \n",
       "219          1303.4058  [[ , single, photon, sources, based, on, semic...   \n",
       "293          0704.3553  [[ , we, show, that, the, centrality, and, sys...   \n",
       "...                ...                                                ...   \n",
       "24544    hep-ph9808244  [[ , the, interplay, between, gaugino, condens...   \n",
       "24569        1102.0174  [[ , while, crystalline, two, -, dimensional, ...   \n",
       "24630    hep-ph0110404  [[ , the, diffractive, photoproduction, of, ve...   \n",
       "24649  quant-ph0402038  [[ , effects, of, a, corrupt, source, on, the,...   \n",
       "24652  cond-mat0304118  [[ , within, the, lowest, -, order, born, appr...   \n",
       "\n",
       "       num_sentences  \n",
       "6                108  \n",
       "156              567  \n",
       "194              303  \n",
       "219              467  \n",
       "293              146  \n",
       "...              ...  \n",
       "24544            103  \n",
       "24569            228  \n",
       "24630            106  \n",
       "24649            155  \n",
       "24652            204  \n",
       "\n",
       "[4497 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['num_sentences']>100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb4a7b62-a258-4941-9062-969b72f5a80c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 2, 9, 4, 4, 4, 108, 6, 9, 5]\n",
      "692\n"
     ]
    }
   ],
   "source": [
    "df = load_data(1)\n",
    "n = ([len(doc) for doc in list(df['sentences'])])\n",
    "print(n[:10])\n",
    "print(max(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db75fc1d-390d-43c0-b485-74c7ee51ba36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sentences</th>\n",
       "      <th>num_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1405.3379</td>\n",
       "      <td>[[ , additive, models, play, an, important, ro...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0901.1147</td>\n",
       "      <td>[[ , we, have, studied, the, leptonic, decay, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nlin0608019</td>\n",
       "      <td>[[ , in, 84, ,, 258, (, 2000, ), ,, mateos, co...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0903.5449</td>\n",
       "      <td>[[ , the, effect, of, a, random, phase, diffus...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hep-ph0605279</td>\n",
       "      <td>[[ , with, a, special, intention, of, clarifyi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35785</th>\n",
       "      <td>0909.5250</td>\n",
       "      <td>[[ , we, investigate, genericities, of, reticu...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35786</th>\n",
       "      <td>1105.1966</td>\n",
       "      <td>[[ , we, report, on, charmonium, measurements,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35787</th>\n",
       "      <td>nucl-th0308087</td>\n",
       "      <td>[[ , recent, measurements, of, the, @xmath0, i...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35788</th>\n",
       "      <td>1010.5262</td>\n",
       "      <td>[[ , we, present, new, ,, high, signal, -, to,...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35789</th>\n",
       "      <td>1301.6135</td>\n",
       "      <td>[[ , in, this, paper, we, study, the, curved, ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35790 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             paper_id                                          sentences  \\\n",
       "0           1405.3379  [[ , additive, models, play, an, important, ro...   \n",
       "1           0901.1147  [[ , we, have, studied, the, leptonic, decay, ...   \n",
       "2         nlin0608019  [[ , in, 84, ,, 258, (, 2000, ), ,, mateos, co...   \n",
       "3           0903.5449  [[ , the, effect, of, a, random, phase, diffus...   \n",
       "4       hep-ph0605279  [[ , with, a, special, intention, of, clarifyi...   \n",
       "...               ...                                                ...   \n",
       "35785       0909.5250  [[ , we, investigate, genericities, of, reticu...   \n",
       "35786       1105.1966  [[ , we, report, on, charmonium, measurements,...   \n",
       "35787  nucl-th0308087  [[ , recent, measurements, of, the, @xmath0, i...   \n",
       "35788       1010.5262  [[ , we, present, new, ,, high, signal, -, to,...   \n",
       "35789       1301.6135  [[ , in, this, paper, we, study, the, curved, ...   \n",
       "\n",
       "       num_sentences  \n",
       "0                  6  \n",
       "1                  2  \n",
       "2                  9  \n",
       "3                  4  \n",
       "4                  4  \n",
       "...              ...  \n",
       "35785              4  \n",
       "35786              4  \n",
       "35787              5  \n",
       "35788             12  \n",
       "35789              7  \n",
       "\n",
       "[35790 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['num_sentences'] = n\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "370ee3e6-8c6d-4d2c-af85-9476a4057568",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"  we note the similarity between bec ( bose - einstein condensates ) formed of atoms between which we have long - range attraction ( and shorter - range repulsions ) and the field theoretic ` ` q balls '' .   \""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for sentences in (df[df['num_sentences']==max(n)]['sentences']):\n",
    "    words = [len(sent) for sent in sentences]\n",
    "    sentences = [\" \".join(sent) for sent in sentences]\n",
    "(len(df_words))\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7a8f67c2-7de7-4e3f-8b5c-c5aeb8d3f81a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we note the similarity between bec ( bose - ...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this allows us in particular to address the st...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phase transitions occur when a change of coupl...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in the field theoretic formulation , this is m...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in a simple mechanical analog the system repre...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>however @xmath0 droplets exist despite the abs...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>could a @xmath0 which is free to move in a pre...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>this is clearly not evident since the nuclear ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>it is amusing to note , however , that the exi...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>the subsequent @xmath214 decay @xmath215 sec l...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>692 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentences  num_words\n",
       "0      we note the similarity between bec ( bose - ...         42\n",
       "1    this allows us in particular to address the st...         50\n",
       "2    phase transitions occur when a change of coupl...         28\n",
       "3    in the field theoretic formulation , this is m...         45\n",
       "4    in a simple mechanical analog the system repre...         25\n",
       "..                                                 ...        ...\n",
       "687  however @xmath0 droplets exist despite the abs...         14\n",
       "688  could a @xmath0 which is free to move in a pre...         34\n",
       "689  this is clearly not evident since the nuclear ...         27\n",
       "690  it is amusing to note , however , that the exi...         42\n",
       "691  the subsequent @xmath214 decay @xmath215 sec l...         37\n",
       "\n",
       "[692 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words = pd.DataFrame(sentences, columns=['sentences'])\n",
    "df_words['num_words'] = words\n",
    "df_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "81d2e3e5-b43e-4f23-b429-6d404ceccbe1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>\\ii )</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>\\ !</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>\\ !</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>\\ !</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>\\ !</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>\\ !</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>\\ !</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>\\ !</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>\\ !</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>system .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentences  num_words\n",
       "164     \\ii )          2\n",
       "172       \\ !          2\n",
       "173       \\ !          2\n",
       "174       \\ !          2\n",
       "175       \\ !          2\n",
       "..        ...        ...\n",
       "649       \\ !          2\n",
       "650       \\ !          2\n",
       "651       \\ !          2\n",
       "652       \\ !          2\n",
       "684  system .          2\n",
       "\n",
       "[480 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words[df_words['num_words']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "86289af6-b06e-4d75-a24c-0cb17e326038",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.213872832369942"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(words)/len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a336e766-b37a-40cf-98ff-de74ee06cd50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59da519a-0f08-405a-b972-d66e45606163",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret input 'num_sentences'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfigure.autolayout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# plt.figure(figsize=(5, 4)) #for a bigger image\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboxplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_sentences\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpalette\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSet1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/seaborn/categorical.py:2231\u001b[0m, in \u001b[0;36mboxplot\u001b[0;34m(data, x, y, hue, order, hue_order, orient, color, palette, saturation, width, dodge, fliersize, linewidth, whis, ax, **kwargs)\u001b[0m\n\u001b[1;32m   2224\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mboxplot\u001b[39m(\n\u001b[1;32m   2225\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, hue_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2226\u001b[0m     orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, palette\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, saturation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.75\u001b[39m, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.8\u001b[39m,\n\u001b[1;32m   2227\u001b[0m     dodge\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fliersize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, whis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.5\u001b[39m, ax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2228\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   2229\u001b[0m ):\n\u001b[0;32m-> 2231\u001b[0m     plotter \u001b[38;5;241m=\u001b[39m \u001b[43m_BoxPlotter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2232\u001b[0m \u001b[43m                          \u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpalette\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaturation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2233\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdodge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfliersize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2235\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2236\u001b[0m         ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mgca()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/seaborn/categorical.py:785\u001b[0m, in \u001b[0;36m_BoxPlotter.__init__\u001b[0;34m(self, x, y, hue, data, order, hue_order, orient, color, palette, saturation, width, dodge, fliersize, linewidth)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y, hue, data, order, hue_order,\n\u001b[1;32m    782\u001b[0m              orient, color, palette, saturation,\n\u001b[1;32m    783\u001b[0m              width, dodge, fliersize, linewidth):\n\u001b[0;32m--> 785\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestablish_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue_order\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestablish_colors(color, palette, saturation)\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdodge \u001b[38;5;241m=\u001b[39m dodge\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/seaborn/categorical.py:541\u001b[0m, in \u001b[0;36m_CategoricalPlotter.establish_variables\u001b[0;34m(self, x, y, hue, data, orient, order, hue_order, units)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(var, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    540\u001b[0m         err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not interpret input \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 541\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n\u001b[1;32m    543\u001b[0m \u001b[38;5;66;03m# Figure out the plotting orientation\u001b[39;00m\n\u001b[1;32m    544\u001b[0m orient \u001b[38;5;241m=\u001b[39m infer_orient(\n\u001b[1;32m    545\u001b[0m     x, y, orient, require_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequire_numeric\n\u001b[1;32m    546\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Could not interpret input 'num_sentences'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the figure size\n",
    "plt.rcParams[\"figure.figsize\"] = [5, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "# plt.figure(figsize=(5, 4)) #for a bigger image\n",
    "sns.boxplot(y=\"num_sentences\", data=df, palette=\"Set1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a76d07b-0eb5-466d-9172-fae8ed7d4f25",
   "metadata": {},
   "source": [
    "# prepareArXiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a2e6c338-b43e-46ab-8c3a-930de012afbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json \n",
    "from pathlib import Path\n",
    "import spacy\n",
    "import argparse\n",
    "\n",
    "def print_progress(curr, full, desc='', bar_size=50):    \n",
    "    bar = int((curr+1)/full*bar_size)\n",
    "    sys.stdout.write(f\"\\r{desc}[{'='*bar}{' '*(bar_size-bar)}] {curr+1}/{full}\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "def load_data(filepath, section):\n",
    "    with open(filepath, 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "    dataset = []\n",
    "    data_len = len(json_list)\n",
    "    cant_load = 0\n",
    "    for i, json_str in enumerate(json_list):\n",
    "        try:\n",
    "            line = json.loads(json_str)\n",
    "            if section==\"abstract\":\n",
    "                dataset.append({\n",
    "                    \"doc_key\": line[\"article_id\"],\n",
    "                    \"sentences\": (\" \".join(line[\"abstract_text\"])).replace(\"<S>\", \"\").replace(\"</S>\", \"\"),\n",
    "                })\n",
    "            elif section[:7]==\"section\":\n",
    "                sec_no = int(section[7:])-1\n",
    "                dataset.append({\n",
    "                    \"doc_key\": line[\"article_id\"],\n",
    "                    \"sentences\": \" \".join(line[\"sections\"][sec_no]),\n",
    "                })\n",
    "        except: \n",
    "            cant_load += 1\n",
    "        print_progress(i, data_len, desc=f'Loading {section} ')\n",
    "    print(f\"\\nSuccessfully import {data_len-cant_load}/{data_len} samples\")\n",
    "    return dataset\n",
    "\n",
    "def convert_data(data):\n",
    "    num_docs = len(data)\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    conv_data = []\n",
    "    for idx, doc in enumerate(data):\n",
    "        conv_data.append({})\n",
    "        doc_text = nlp(doc[\"sentences\"])\n",
    "        sents, ners, rels = [], [], []\n",
    "        for sent in doc_text.sents:\n",
    "            token_sent = [str(tok) for tok in sent]\n",
    "            sents.append(token_sent)\n",
    "            ners.append([])\n",
    "            rels.append([])\n",
    "        print_progress(idx, num_docs,  desc='Converting data ')\n",
    "        conv_data[idx][\"doc_key\"] = doc[\"doc_key\"]\n",
    "        conv_data[idx][\"sentences\"] = sents\n",
    "        conv_data[idx][\"ner\"] = ners\n",
    "        conv_data[idx][\"relations\"] = rels\n",
    "    print()\n",
    "    return conv_data\n",
    "\n",
    "def export_data(data, output_dir, filename, file_size_limit=float('inf')):\n",
    "    print(\"Writing prepared data to jsonl file\")\n",
    "    print(output_dir)\n",
    "    if not(Path(output_dir).exists()): os.system(f\"mkdir -p {output_dir}\")\n",
    "    \n",
    "    # Convert MB to bytes\n",
    "    if file_size_limit!=float('inf'):\n",
    "        file_size_limit = int(file_size_limit*pow(1024,2)*0.95)\n",
    "    \n",
    "    file_size = 0\n",
    "    file_number = 1\n",
    "    recored = 0\n",
    "    with open(f\"{output_dir}{filename}.jsonl\", \"w\") as f:\n",
    "        for idx, line in enumerate(data):\n",
    "            json_str = json.dumps(line, ensure_ascii=False)\n",
    "            file_size += len(json_str.encode('utf-8')) + 1 \n",
    "            if file_size > file_size_limit:\n",
    "                f.close()\n",
    "                if file_number==1:\n",
    "                    os.rename(f\"{output_dir}{filename}.jsonl\", f\"{output_dir}{filename}_{file_number}.jsonl\")    \n",
    "                print(f'\\tWrote {idx-recored} records (({file_size/pow(1024,2):.3f}MB)) to {output_dir}{filename}_{file_number}.')\n",
    "                recored = idx\n",
    "                file_number += 1\n",
    "                file_size = 0\n",
    "                f = open(f\"{output_dir}{filename}_{file_number}.jsonl\", \"w\")\n",
    "            f.write(json_str + '\\n')\n",
    "    if file_number==1:\n",
    "        print(f'Successfully wrote {len(data)} records ({file_size/pow(1024,2):.3f}MB) to {output_dir}{filename}')\n",
    "    else:\n",
    "        print(f'\\tWrote {idx-recored} records (({file_size/pow(1024,2):.3f}MB)) to {output_dir}{filename}_{file_number}.')\n",
    "        print(f'Successfully wrote {len(data)} records to {file_number} output files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b88dc0-cb36-4d75-84af-fefc3de36cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"train\"\n",
    "\n",
    "data = load_data(f\"{dataset_path}{key}.txt\", args.section)\n",
    "data = convert_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da6aca0-33d4-46f1-b450-bad6d2c60ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdd2815-59ad-4cdd-9678-8d1b831b5326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4eb8ad-c10b-4a15-9e4a-55fe7521eca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba074ac-cd8c-4ad1-815a-c8de6eebd070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edcff510-c819-420d-923c-519f61dbf042",
   "metadata": {},
   "source": [
    "# Record for getNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "faf410b7-7bfb-45a1-8de7-6333c332b1ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m file_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPL-Marker/log/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_getNER_status_train_2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_dir\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mfile_name\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m df\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:678\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    663\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    664\u001b[0m     dialect,\n\u001b[1;32m    665\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    674\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    675\u001b[0m )\n\u001b[1;32m    676\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:581\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1253\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1251\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1253\u001b[0m     index, columns, col_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py:225\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 225\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    227\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:805\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:847\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1960\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "file_dir = \"PL-Marker/log/\"\n",
    "file_name = \"run_getNER_status_train_2\"\n",
    "df = pd.read_csv(file_dir+file_name+\".csv\", index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2f4b1b-2cc4-4270-9180-5c3cd725656e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_string = df['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b3e7f5-cdc7-472f-afcd-583cda6f4be5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "my_list = ast.literal_eval(my_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34c7a50-ff27-47e2-982e-956aaddb9372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sample in my_list:\n",
    "    print(len(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a5db13-e0e5-42b3-8155-e46291878135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "588f3a93-c927-495e-9a93-0d27694fbb19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(filepath, section):\n",
    "    with open(filepath, 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "    dataset = []\n",
    "    data_len = len(json_list)\n",
    "    cant_load = loaded = 0\n",
    "    for i, json_str in enumerate(json_list):\n",
    "        try:\n",
    "            line = json.loads(json_str)\n",
    "            if section==\"abstract\":\n",
    "                dataset.append({\n",
    "                    \"doc_key\": line[\"article_id\"],\n",
    "                    \"sentences\": line[\"abstract_text\"],\n",
    "                    # \"sentences\": (\" \".join(line[\"abstract_text\"])).replace(\"<S> \", \"\").replace(\" </S>\", \"\"),\n",
    "                })\n",
    "            elif section[:7]==\"section\":\n",
    "                sec_no = int(section[7:])-1\n",
    "                dataset.append({\n",
    "                    \"doc_key\": line[\"article_id\"],\n",
    "                    \"sentences\": \" \".join(line[\"sections\"][sec_no]),\n",
    "                })\n",
    "            loaded += 1\n",
    "        except: \n",
    "            cant_load += 1\n",
    "        # if i>=100: break\n",
    "    print(f\"\\nSuccessfully import {loaded}/{data_len} samples\")\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f8d7ac72-6a50-4790-bcf2-c0ae39a9b21b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def drop_outlier(data):\n",
    "    data = pd.DataFrame(data)\n",
    "    data['num_sentences'] = [len(sent) for sent in (data['sentences'])]\n",
    "    data = data[data['num_sentences']<200]\n",
    "    data = data.drop('num_sentences', axis=1)\n",
    "    data = data.to_dict('records')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b9c5e2df-3938-4a72-bca9-34a2302b35b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully import 203037/203037 samples\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json \n",
    "from pathlib import Path\n",
    "\n",
    "dataset_path = str(Path().absolute())+\"/dataset_arXiv/\"\n",
    "key = \"train\"\n",
    "data = load_data(f\"{dataset_path}{key}.txt\", \"abstract\")\n",
    "# data = pd.DataFrame(data)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "82822a3e-e6ad-4692-a59a-f638bb69fde7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_data(data):\n",
    "    print(\"Start converting data\", len(data))\n",
    "    data = drop_outlier(data)\n",
    "    print(\"Start converting data\", len(data))\n",
    "    \n",
    "    num_docs = len(data)\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    conv_data = []\n",
    "    for idx, doc in enumerate(data):\n",
    "        conv_data.append({})\n",
    "        # doc_text = nlp(doc[\"sentences\"])\n",
    "        sents, ners, rels = [], [], []\n",
    "        for sent in doc['sentences']:\n",
    "            sent = sent.replace(\"<S> \", \"\").replace(\" </S>\", \"\")\n",
    "            sent = nlp(sent)\n",
    "            token_sent = [token.text for token in sent]\n",
    "            sents.append(token_sent)\n",
    "            ners.append([])\n",
    "            rels.append([])\n",
    "        # print_progress(idx, num_docs,  desc='Converting data ')\n",
    "        conv_data[idx][\"doc_key\"] = doc[\"doc_key\"]\n",
    "        conv_data[idx][\"sentences\"] = sents\n",
    "        conv_data[idx][\"ner\"] = ners\n",
    "        conv_data[idx][\"relations\"] = rels\n",
    "    return conv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1fb9c124-86d2-46d3-ad2c-dc80b7667778",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start converting data 203037\n",
      "Start converting data 202284\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m conv_data \u001b[38;5;241m=\u001b[39m (\u001b[43mconvert_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mlen\u001b[39m(conv_data)\n",
      "Cell \u001b[0;32mIn[113], line 15\u001b[0m, in \u001b[0;36mconvert_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m doc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentences\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     14\u001b[0m     sent \u001b[38;5;241m=\u001b[39m sent\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<S> \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m </S>\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     token_sent \u001b[38;5;241m=\u001b[39m [token\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m sent]\n\u001b[1;32m     17\u001b[0m     sents\u001b[38;5;241m.\u001b[39mappend(token_sent)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/language.py:1011\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1011\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mproc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcomponent_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1013\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/pipeline/attributeruler.py:143\u001b[0m, in \u001b[0;36mAttributeRuler.__call__\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    141\u001b[0m error_handler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     matches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_annotations(doc, matches)\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m doc\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/pipeline/attributeruler.py:150\u001b[0m, in \u001b[0;36mAttributeRuler.match\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmatch\u001b[39m(\u001b[38;5;28mself\u001b[39m, doc: Doc):\n\u001b[0;32m--> 150\u001b[0m     matches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_missing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_spans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# Sort by the attribute ID, so that later rules have precedence\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     matches \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    153\u001b[0m         (\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab\u001b[38;5;241m.\u001b[39mstrings[m_id]), m_id, s, e) \u001b[38;5;28;01mfor\u001b[39;00m m_id, s, e \u001b[38;5;129;01min\u001b[39;00m matches  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     ]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "conv_data = (convert_data(data))\n",
    "len(conv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "51aa1df9-b5b3-4be2-be18-5e875d9bc1f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<S> additive models play an important role in semiparametric statistics . </S>',\n",
       " '<S> this paper gives learning rates for regularized kernel based methods for additive models . </S>',\n",
       " '<S> these learning rates compare favourably in particular in high dimensions to recent results on optimal learning rates for purely nonparametric regularized kernel based quantile regression using the gaussian radial basis function kernel , provided the assumption of an additive model is valid . </S>',\n",
       " '<S> additionally , a concrete example is presented to show that a gaussian function depending only on one variable lies in a reproducing kernel hilbert space generated by an additive gaussian kernel , but does not belong to the reproducing kernel hilbert space generated by the multivariate gaussian kernel of the same variance .    * </S>',\n",
       " '<S> key words and phrases . * additive model , kernel , quantile regression , semiparametric , rate of convergence , support vector machine . </S>']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_outlier(data)[0]['sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "66f32916-3ac5-4544-bd06-5573e3c1370e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_key</th>\n",
       "      <th>sentences</th>\n",
       "      <th>num_sent</th>\n",
       "      <th>num_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1405.3379</td>\n",
       "      <td>[&lt;S&gt; additive models play an important role in...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0901.1147</td>\n",
       "      <td>[&lt;S&gt; we have studied the leptonic decay @xmath...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nlin0608019</td>\n",
       "      <td>[&lt;S&gt; in 84 , 258 ( 2000 ) , mateos conjectured...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0903.5449</td>\n",
       "      <td>[&lt;S&gt; the effect of a random phase diffuser on ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hep-ph0605279</td>\n",
       "      <td>[&lt;S&gt; with a special intention of clarifying th...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203032</th>\n",
       "      <td>quant-ph0402038</td>\n",
       "      <td>[&lt;S&gt; effects of a corrupt source on the dynami...</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203033</th>\n",
       "      <td>0907.3736</td>\n",
       "      <td>[&lt;S&gt; we compute the entropy of antiferromagnet...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203034</th>\n",
       "      <td>1506.04688</td>\n",
       "      <td>[&lt;S&gt; as a generalization of orbit - polynomial...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203035</th>\n",
       "      <td>cond-mat0304118</td>\n",
       "      <td>[&lt;S&gt; within the lowest - order born approximat...</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203036</th>\n",
       "      <td>0801.2228</td>\n",
       "      <td>[&lt;S&gt; conducting submicron particles are well -...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203037 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                doc_key                                          sentences  \\\n",
       "0             1405.3379  [<S> additive models play an important role in...   \n",
       "1             0901.1147  [<S> we have studied the leptonic decay @xmath...   \n",
       "2           nlin0608019  [<S> in 84 , 258 ( 2000 ) , mateos conjectured...   \n",
       "3             0903.5449  [<S> the effect of a random phase diffuser on ...   \n",
       "4         hep-ph0605279  [<S> with a special intention of clarifying th...   \n",
       "...                 ...                                                ...   \n",
       "203032  quant-ph0402038  [<S> effects of a corrupt source on the dynami...   \n",
       "203033        0907.3736  [<S> we compute the entropy of antiferromagnet...   \n",
       "203034       1506.04688  [<S> as a generalization of orbit - polynomial...   \n",
       "203035  cond-mat0304118  [<S> within the lowest - order born approximat...   \n",
       "203036        0801.2228  [<S> conducting submicron particles are well -...   \n",
       "\n",
       "        num_sent  num_sentences  \n",
       "0              5              5  \n",
       "1              2              2  \n",
       "2              9              9  \n",
       "3              4              4  \n",
       "4              4              4  \n",
       "...          ...            ...  \n",
       "203032       118            118  \n",
       "203033         6              6  \n",
       "203034         6              6  \n",
       "203035       175            175  \n",
       "203036         3              3  \n",
       "\n",
       "[203037 rows x 4 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['num_sentences'] = [len(sent) for sent in (data['sentences'])]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9b4e8647-e25d-48f9-94c0-7144a8f27a06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data[data['num_sentences']<200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c80e580b-395e-4592-9d45-ad3eedf0d6f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_key</th>\n",
       "      <th>sentences</th>\n",
       "      <th>num_sent</th>\n",
       "      <th>num_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1405.3379</td>\n",
       "      <td>[&lt;S&gt; additive models play an important role in...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0901.1147</td>\n",
       "      <td>[&lt;S&gt; we have studied the leptonic decay @xmath...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nlin0608019</td>\n",
       "      <td>[&lt;S&gt; in 84 , 258 ( 2000 ) , mateos conjectured...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0903.5449</td>\n",
       "      <td>[&lt;S&gt; the effect of a random phase diffuser on ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hep-ph0605279</td>\n",
       "      <td>[&lt;S&gt; with a special intention of clarifying th...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203032</th>\n",
       "      <td>quant-ph0402038</td>\n",
       "      <td>[&lt;S&gt; effects of a corrupt source on the dynami...</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203033</th>\n",
       "      <td>0907.3736</td>\n",
       "      <td>[&lt;S&gt; we compute the entropy of antiferromagnet...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203034</th>\n",
       "      <td>1506.04688</td>\n",
       "      <td>[&lt;S&gt; as a generalization of orbit - polynomial...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203035</th>\n",
       "      <td>cond-mat0304118</td>\n",
       "      <td>[&lt;S&gt; within the lowest - order born approximat...</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203036</th>\n",
       "      <td>0801.2228</td>\n",
       "      <td>[&lt;S&gt; conducting submicron particles are well -...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202284 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                doc_key                                          sentences  \\\n",
       "0             1405.3379  [<S> additive models play an important role in...   \n",
       "1             0901.1147  [<S> we have studied the leptonic decay @xmath...   \n",
       "2           nlin0608019  [<S> in 84 , 258 ( 2000 ) , mateos conjectured...   \n",
       "3             0903.5449  [<S> the effect of a random phase diffuser on ...   \n",
       "4         hep-ph0605279  [<S> with a special intention of clarifying th...   \n",
       "...                 ...                                                ...   \n",
       "203032  quant-ph0402038  [<S> effects of a corrupt source on the dynami...   \n",
       "203033        0907.3736  [<S> we compute the entropy of antiferromagnet...   \n",
       "203034       1506.04688  [<S> as a generalization of orbit - polynomial...   \n",
       "203035  cond-mat0304118  [<S> within the lowest - order born approximat...   \n",
       "203036        0801.2228  [<S> conducting submicron particles are well -...   \n",
       "\n",
       "        num_sent  num_sentences  \n",
       "0              5              5  \n",
       "1              2              2  \n",
       "2              9              9  \n",
       "3              4              4  \n",
       "4              4              4  \n",
       "...          ...            ...  \n",
       "203032       118            118  \n",
       "203033         6              6  \n",
       "203034         6              6  \n",
       "203035       175            175  \n",
       "203036         3              3  \n",
       "\n",
       "[202284 rows x 4 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a790e9d0-a013-4d2c-b65e-43982f67d96b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3664f7a4-66ef-4d16-8678-66f97af7b2d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#comment this if you are not using puffer?\n",
    "os.environ['http_proxy'] = 'http://192.41.170.23:3128'\n",
    "os.environ['https_proxy'] = 'http://192.41.170.23:3128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cf318c0-3b33-4e55-92f7-7c8279466bd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "example = \"My sister has a dog. She loves him.\"\n",
    "\n",
    "\n",
    "doc.spans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5564da99-3d1e-4567-9d26-a977b0c99495",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'neuralcoref.neuralcoref.array' has no attribute '__reduce_cython__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mneuralcoref\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# nlp = spacy.load('en')\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# neuralcoref.add_to_pipe(nlp)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# doc1 = nlp('My sister has a dog. She loves him.')\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# for ent in doc2.ents:\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#     print(ent._.coref_cluster)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/neuralcoref/__init__.py:14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     12\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspacy.strings.StringStore size changed,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneuralcoref\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NeuralCoref\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NEURALCOREF_MODEL_URL, NEURALCOREF_MODEL_PATH, NEURALCOREF_CACHE, cached_path\n\u001b[1;32m     17\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNeuralCoref\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd_to_pipe\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32mstringsource:105\u001b[0m, in \u001b[0;36minit neuralcoref.neuralcoref\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'neuralcoref.neuralcoref.array' has no attribute '__reduce_cython__'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import neuralcoref\n",
    "\n",
    "# nlp = spacy.load('en')\n",
    "# neuralcoref.add_to_pipe(nlp)\n",
    "# doc1 = nlp('My sister has a dog. She loves him.')\n",
    "# print(doc1._.coref_clusters)\n",
    "\n",
    "# doc2 = nlp('Angela lives in Boston. She is quite happy in that city.')\n",
    "# for ent in doc2.ents:\n",
    "#     print(ent._.coref_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4880c8e3-ed5b-477f-b2d8-a1b7fbcfdd3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'led'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"led-base\"\n",
    "model.split(\"-\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4db9df8-860d-43c8-a157-e717128b2558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
